


\begin{itemize}
	\item Kernel approximation methods are used in order to scale kernel methods to large datasets.  Two leading methods are the \Nystrom method and random Fourier features.
	\item We provide a thorough empirical comparison between these methods
	\item Provide a brief survey of kernel approximation generalization bounds.
	\item Shortcomings of these bounds: (1) Computation/memory is generally ignored in these bounds, (2) they often depend on the Frobenius/spectral norm of error matrix, and thus cannot explain differences in performance between two kernel approximations with the same error norm.
	\item Both of these shortcoming generally lead to the simplistic conclusion ``\Nystrom is better''.
	\item We show that the truth is much more complicated. 
\end{itemize}